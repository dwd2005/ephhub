**潜在问题分析**
1. 复制/导入的目标路径可能发生重命名  
`copy/importExternal` 会在目标名冲突时自动改名，但操作记录使用的是“预估目标”，导致 `operationTracker` 无法匹配 watcher 事件。  
建议：在复制/导入完成后主动 `syncNow`，或在文件系统层拿到最终路径后写回 `metaByPath`。

2. 路径队列粒度可能偏粗  
当前路径关联键以“根目录下一级”为单位，同一一级目录内的并发会被串行，但更深层次的强关联路径仍可能并行，存在顺序错位风险。  
建议：对 `move/rename/delete` 等高风险操作使用更细粒度的 key（如完整路径），或根据操作类型动态调整粒度。

3. `syncNow` 只覆盖部分关键流程  
目前 `move/rename` 主动 `syncNow`，`delete/copy/clean-temp` 仍依赖 watcher 或超时兜底，出现“事件丢失”时会延迟修复。  
建议：对 `delete/copy` 等操作在成功后补一次轻量同步，或在 watcher 事件缺失时触发快速兜底。

4. 错误重试可能导致重复执行  
前端“重试”会再次发起相同操作，如果上一次操作已成功但响应失败，会造成重复执行。  
建议：重试前先刷新当前目录状态，或弹窗提示“可能已执行成功，请先刷新确认”。

**性能优化点**
1. 批量写入进一步优化  
当前 `upsertFiles/upsertFileTypes` 虽使用事务，但仍逐条 `run`，在大量文件时开销较高。  
建议：采用批量 `INSERT ... VALUES (...)`，按 200~500 条分批提交，减少 SQL 往返。

2. `IN` 参数上限风险  
`getInfo/deleteRecords` 使用 `IN` 拼接，当路径过多会触发 SQLite 参数上限。  
建议：分批执行或使用临时表 + `JOIN` 的方式查询/删除。

3. `buildTimeBuckets` 频繁 `stat`  
时间视图在未设置自定义时间时逐个 `stat`，文件量大时耗时明显。  
建议：增加 `effective_time` 缓存字段，首次计算后写入 DB，后续直接读取。

4. `listDirectory` 串行 `stat`  
大量子项会导致目录进入速度变慢。  
建议：使用并发限制的 `Promise.all`（如 16~32 并发），提高 I/O 吞吐。

5. watcher 事件风暴  
大规模操作可能触发大量 watcher 事件，导致频繁写库和 UI 刷新。  
建议：对 watcher 事件做时间窗口合并（节流/批处理），减少频繁刷新。

6. `scanRoot` 全量遍历耗时与内存  
当前先收集后写入，目录很大时内存压力高。  
建议：边遍历边分批写入，或采用流式遍历。
